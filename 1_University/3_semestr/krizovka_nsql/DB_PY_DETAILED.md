# db.py - PodrobnÃ© VysvÄ›tlenÃ­

## ğŸ“š STRUKTURA (286 Å™Ã¡dkÅ¯)

```
Imports (1-13)
  â†“
DatabaseManager class (18-286)
  â”œâ”€ __init__ (21-29) - Inicializace
  â”œâ”€ @property mongo (31-48) - Lazy-load MongoDB
  â”œâ”€ @property redis (50-62) - Lazy-load Redis
  â”œâ”€ @property db (64-69) - PÅ™Ã­stup k DB
  â”œâ”€ get_collection (71-73) - VraÅ¥ MongoDB kolekci
  â”œâ”€ clear_all_events (76-89) - SmaÅ¾ vÅ¡echny eventy
  â”œâ”€ create_event (91-107) - VytvoÅ™ novÃ½ event
  â”œâ”€ get_event (109-123) - NaÄti event podle ID
  â”œâ”€ get_all_events (125-173) - NaÄti vÅ¡echny (s cachovÃ¡nÃ­m)
  â”œâ”€ get_events_by_severity (175-189) - Filtruj podle zÃ¡vaÅ¾nosti
  â”œâ”€ count_events (191-213) - PoÄet eventÅ¯ (s cachovÃ¡nÃ­m)
  â”œâ”€ count_today_events (215-246) - DneÅ¡nÃ­ eventy
  â”œâ”€ delete_event (248-262) - SmaÅ¾ event
  â”œâ”€ _invalidate_events_cache (264-269) - VymaÅ¾ cache
  â””â”€ health_check (271-286) - OvÄ›Å™ spojenÃ­
```

---

## ğŸ”Œ IMPORTS

```python
from typing import List, Dict, Any, Optional  # Type hints
from datetime import datetime                  # Pro created_at
import json                                    # Serialization
import logging                                 # LogovÃ¡nÃ­

from pymongo import MongoClient, DESCENDING   # MongoDB driver
from pymongo.errors import ConnectionFailure, ServerSelectionTimeoutError
import redis                                   # Redis cache

from .models import CrisisEvent                # NÃ¡Å¡ datovÃ½ model
```

---

## ğŸ—ï¸ ARCHITEKTURA: 2 DATABÃZE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DatabaseManager (SprÃ¡vce dat)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  â”‚                                      â”‚
â”‚   MongoDB        â”‚           Redis Cache                â”‚
â”‚  (Persistent)    â”‚        (In-Memory)                   â”‚
â”‚                  â”‚                                      â”‚
â”‚ âœ“ TrvalÃ½ Ãºklod   â”‚  âœ“ RychlÃ½ pÅ™Ã­stup                   â”‚
â”‚ âœ“ ZapytovÃ¡nÃ­     â”‚  âœ“ 5 minut TTL (auto-delete)        â”‚
â”‚ âœ“ FiltrovÃ¡nÃ­     â”‚  âœ“ Invalidace na create/delete       â”‚
â”‚                  â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ LAZY LOADING - KLÃÄŒOVÃ KONCEPT!

```python
def __init__(self, mongo_uri: str, redis_url: str, db_name: str):
    self.mongo_uri = mongo_uri
    self.redis_url = redis_url
    self.db_name = db_name
    
    # ZATÃM NIÄŒEHO NEINICIALIZUJEME!
    self._mongo_client: Optional[MongoClient] = None
    self._redis_client: Optional[redis.Redis] = None
    self._db = None
```

**Co to znamenÃ¡:**
- `self._mongo_client = None` â†’ MongoDB nenÃ­ pÅ™ipojen
- PÅ™ipojÃ­me se aÅ¾ kdyÅ¾ si ho PrvnÃ­ zaÅ¾Ã¡dÃ¡me
- = HeÅ¡Ã­ startup aplikace (vÅ¡echna pÅ™ipojenÃ­ se dÄ›jÃ­ asynchronÄ›)

### **PÅ™Ã­klad:**
```python
db = DatabaseManager(mongo_uri, redis_url, "krizove_udalosti")
# ZatÃ­m nic - MongoDB/Redis nevÃ­me

event = db.get_event("123")
# TEÄ se poprvÃ© pÅ™ipojÃ­ k MongoDB (lazy load)
```

---

## ğŸ”— LAZY-LOAD MONGODB

```python
@property
def mongo(self) -> MongoClient:
    """Lazy-load MongoDB connection"""
    if self._mongo_client is None:  # Pokud jeÅ¡tÄ› nenÃ­ pÅ™ipojen
        try:
            # PÅ™ipoj se s 5-sekundovÃ½m timeoutem
            self._mongo_client = MongoClient(self.mongo_uri, serverSelectionTimeoutMS=5000)
            
            # TEST: Zda je MongoDB online
            self._mongo_client.server_info()
            
            # PÅ™ipoj se k databÃ¡zi
            self._db = self._mongo_client[self.db_name]
            
            logger.info(f"âœ“ PÅ™ipojen k MongoDB: {self.db_name}")
        except (ConnectionFailure, ServerSelectionTimeoutError) as e:
            logger.error(f"âœ— MongoDB spojenÃ­ selhalo: {e}")
            self._mongo_client = None
            raise
    return self._mongo_client
```

**Co se dÄ›je:**
1. KdyÅ¾ volÃ¡Å¡ `db.mongo`, Python zkontroluje `if self._mongo_client is None`
2. Pokud je `None`, vytvoÅ™Ã­ novÃ© spojenÃ­
3. ZavolÃ¡ `server_info()` = ovÄ›Å™Ã­ Å¾e MongoDB bÄ›Å¾Ã­
4. Pokud selhÃ¡ â†’ log error + vyhodÃ­ exception

**Chyby:**
- `ConnectionFailure` = MongoDB nenÃ­ dostupnÃ½
- `ServerSelectionTimeoutMS=5000` = maximÃ¡lnÄ› 5 sekund ÄekÃ¡nÃ­

---

## ğŸ”— LAZY-LOAD REDIS

```python
@property
def redis(self) -> redis.Redis:
    """Lazy-load Redis connection"""
    if self._redis_client is None:
        try:
            # PÅ™ipoj se z URL (redis://localhost:6379/0)
            self._redis_client = redis.from_url(self.redis_url, decode_responses=True)
            
            # TEST: ping
            self._redis_client.ping()
            
            logger.info("âœ“ PÅ™ipojen k Redis")
        except Exception as e:
            logger.error(f"âœ— Redis spojenÃ­ selhalo: {e}")
            self._redis_client = None
            raise
    return self._redis_client
```

**KlÃ­ÄovÃ½ parametr:**
- `decode_responses=True` = vracÃ­ stringy mÃ­sto bytes
- Jinak by bylo: `b"hello"` mÃ­sto `"hello"`

---

## ğŸ“Š PÅ˜ÃSLUÅ NÃ METODA: GET COLLECTION

```python
def get_collection(self, name: str):
    """VraÅ¥ MongoDB kolekci"""
    return self.db[name]
```

**PÅ™Ã­klad:**
```python
events_collection = db.get_collection("events")
# = db._db["events"]

users_collection = db.get_collection("users")
# = db._db["users"]
```

---

## ğŸ”¨ OPERACE S EVENTS

### **1. CLEAR_ALL_EVENTS - SmaÅ¾ vÅ¡e**

```python
def clear_all_events(self) -> int:
    """SmaÅ¾ VÅ ECHNY eventy z databÃ¡ze. VrÃ¡tÃ­ poÄet smazanÃ½ch."""
    try:
        collection = self.get_collection("events")
        result = collection.delete_many({})  # {} = vÅ¡echny dokumenty
        
        # Invaliduj vÅ¡echny cache
        self._invalidate_events_cache()
        self.redis.delete("events:today")
        
        logger.info(f"âœ“ SmazÃ¡no {result.deleted_count} eventÅ¯")
        return result.deleted_count
    except Exception as e:
        logger.error(f"âœ— Chyba: {e}")
        raise
```

**Rozklad:**
- `delete_many({})` = smaÅ¾ vÅ¡echny dokumenty
- VrÃ¡tÃ­ `result.deleted_count` = kolik bylo smazanÃ½ch
- Invaliduje cache = dalÅ¡Ã­ `.get_all_events()` pÅ™eÄte z DB

**PÅ™Ã­klad:**
```python
deleted = db.clear_all_events()
print(deleted)  # Output: 17 (smazÃ¡no 17 eventÅ¯)
```

---

### **2. CREATE_EVENT - VytvoÅ™ novÃ½ event**

```python
def create_event(self, event: CrisisEvent) -> str:
    """VytvoÅ™ novou crisis event. VrÃ¡tÃ­ event ID."""
    try:
        collection = self.get_collection("events")
        event_dict = event.to_dict()  # CrisisEvent â†’ dict
        result = collection.insert_one(event_dict)  # UloÅ¾ do MongoDB
        
        # Invaliduj cache
        self._invalidate_events_cache()
        
        logger.info(f"âœ“ Event vytoÅ™en: {result.inserted_id}")
        return str(result.inserted_id)
    except Exception as e:
        logger.error(f"âœ— Chyba: {e}")
        raise
```

**Rozklad:**
1. `event.to_dict()` = konvertuj CrisisEvent na dict (viz models.py)
2. `insert_one(event_dict)` = vloÅ¾ do MongoDB
3. MongoDB automaticky generuje `_id` (ObjectId)
4. `result.inserted_id` = vraÅ¥ MongoDB ID
5. VymaÅ¾ cache (`events:all`, `events:count`) aby se pÅ™Ã­Å¡tÄ› pÅ™eÄetlo z DB

**PÅ™Ã­klad:**
```python
event = CrisisEvent(
    title="PoÅ¾Ã¡r",
    description="...",
    location="Praha",
    severity=4,
    event_type="poÅ¾Ã¡r"
)
event_id = db.create_event(event)
print(event_id)  # Output: "507f1f77bcf86cd799439011" (string!)
```

---

### **3. GET_EVENT - NaÄti event podle ID**

```python
def get_event(self, event_id: str) -> Optional[CrisisEvent]:
    """VraÅ¥ event podle ID"""
    try:
        from bson.objectid import ObjectId
        collection = self.get_collection("events")
        event_dict = collection.find_one({"_id": ObjectId(event_id)})
        if event_dict:
            return CrisisEvent.from_dict(event_dict)
        return None
    except Exception as e:
        logger.error(f"âœ— Chyba: {e}")
        return None
```

**Rozklad:**
1. `ObjectId(event_id)` = konvertuj string na ObjectId (MongoDB formÃ¡t)
2. `find_one({"_id": ObjectId(...)})` = najdi document s tÃ­m ID
3. Pokud je `None` â†’ vraÅ¥ `None` (event neexistuje)
4. Pokud existuje â†’ `from_dict()` ho konvertuj na CrisisEvent objekt

**PÅ™Ã­klad:**
```python
event = db.get_event("507f1f77bcf86cd799439011")
if event:
    print(event.title)  # Output: "PoÅ¾Ã¡r"
else:
    print("Event nenalezen")
```

---

### **4. GET_ALL_EVENTS - NejdÅ¯leÅ¾itÄ›jÅ¡Ã­ (s cachovÃ¡nÃ­m!)**

```python
def get_all_events(self, limit: int = 100, skip: int = 0) -> List[CrisisEvent]:
    """
    VraÅ¥ vÅ¡echny eventy seÅ™azenÃ© podle Äasu (nejnovÄ›jÅ¡Ã­ prvnÃ­).
    Cache se pouÅ¾Ã­vÃ¡ jen kdyÅ¾ nenÃ­ pagination.
    """
    
    # KROK 1: ZKUS CACHE
    cache_key = "events:all"
    if limit == 100 and skip == 0:  # Jen pokud NENÃ pagination
        try:
            cached = self.redis.get(cache_key)
            if cached:
                data = json.loads(cached)  # Deserializuj JSON
                return [CrisisEvent.from_dict(d) for d in data]  # VraÅ¥ z cache
        except Exception as e:
            logger.warning(f"Cache failed: {e}")  # Fallback
    
    # KROK 2: POKUD CACHE SELHAL NEBO JE PAGINATION â†’ MONGODB
    try:
        collection = self.get_collection("events")
        events_data = list(
            collection.find()                          # Najdi vÅ¡echny
            .sort("created_at", DESCENDING)            # SeÅ™aÄ novÄ› â†’ starÃ©
            .limit(limit)                              # Omez vÃ½sledky
            .skip(skip)                                # PÅ™eskoÄ
        )
        
        events = [CrisisEvent.from_dict(d) for d in events_data]
        
        # KROK 3: CACHUJ (jen bez pagination)
        if limit == 100 and skip == 0:
            try:
                self.redis.setex(
                    cache_key,
                    300,  # 5 minut TTL
                    json.dumps([e.to_dict() for e in events], default=str)
                )
            except Exception as e:
                logger.warning(f"Cache write failed: {e}")
        
        return events
    except Exception as e:
        logger.error(f"âœ— Chyba: {e}")
        return []
```

**ARCHITEKTURA CACHOVÃNÃ:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VolÃ¡Å¡: db.get_all_events()         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚
â”‚  Krok 1: limit=100 && skip=0?       â”‚
â”‚    â”œâ”€ ANO: Zkus Redis cache         â”‚
â”‚    â”‚   â”œâ”€ Cache HIT: VraÅ¥ z Redis   â”‚ (RYCHLE - millisekund)
â”‚    â”‚   â””â”€ Cache MISS: Jdi na krok 2 â”‚
â”‚    â””â”€ NE: Jdi na krok 2             â”‚
â”‚                                     â”‚
â”‚  Krok 2: ÄŒti z MongoDB              â”‚
â”‚    â”œâ”€ find() vÅ¡echny documenty      â”‚ (POMALÃ‰ - sekundy)
â”‚    â”œâ”€ sort() od nejnovÄ›jÅ¡Ã­ho        â”‚
â”‚    â”œâ”€ limit() max N resultÅ¯         â”‚
â”‚    â””â”€ skip() pÅ™eskoÄ N              â”‚
â”‚                                     â”‚
â”‚  Krok 3: limit=100 && skip=0?       â”‚
â”‚    â”œâ”€ ANO: Cachuj do Redis na 5 min â”‚
â”‚    â””â”€ NE: Necachuj                  â”‚
â”‚                                     â”‚
â”‚  VraÅ¥ CrisisEvent objekty           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ProÄ se cachuje jen bez pagination?**
- `limit=100, skip=0` = vÅ¡echny events (nejtypiÄtÄ›jÅ¡Ã­ dotaz)
- `limit=10, skip=10` = page 2 (ostatnÃ­ strÃ¡nky se nepouÅ¾Ã­vajÃ­ Äasto)
- Cache by zabrala moc pamÄ›ti

**PÅ™Ã­klady:**
```python
# CACHE HIT (Äte se z Redis za ms)
events = db.get_all_events()  # limit=100, skip=0
# Redis vrÃ¡tÃ­: [{"_id": ..., "title": "PoÅ¾Ã¡r", ...}, ...]

# CACHE MISS (Äte se z MongoDB za sekundy)
events = db.get_all_events(limit=10, skip=0)  # Pagination
# MongoDB: find().limit(10).skip(0)
# NeuklÃ¡dÃ¡ se do Redis

# CACHE HIT (2. volÃ¡nÃ­ stejnÃ©ho dotazu)
events = db.get_all_events()  # limit=100, skip=0
# Redis vrÃ¡tÃ­ STEJNÃ data (dokud nevyprÅ¡Ã­ 5 minut)
```

---

### **5. GET_EVENTS_BY_SEVERITY - Filtruj**

```python
def get_events_by_severity(self, min_severity: int = 1, max_severity: int = 5) -> List[CrisisEvent]:
    """VraÅ¥ eventy urÄitÃ©ho stupnÄ› zÃ¡vaÅ¾nosti"""
    try:
        collection = self.get_collection("events")
        events_data = list(
            collection.find(
                {"severity": {"$gte": min_severity, "$lte": max_severity}}
            )
            .sort("created_at", DESCENDING)
        )
        return [CrisisEvent.from_dict(d) for d in events_data]
    except Exception as e:
        logger.error(f"âœ— Chyba: {e}")
        return []
```

**MongoDB query:**
- `$gte` = greater than or equal (â‰¥)
- `$lte` = less than or equal (â‰¤)
- `{"severity": {"$gte": 3, "$lte": 5}}` = severity 3, 4 nebo 5

**PÅ™Ã­klad:**
```python
# Jen kritickÃ© (severity 4-5)
critical = db.get_events_by_severity(4, 5)

# VÅ¡echny (severity 1-5)
all = db.get_events_by_severity(1, 5)
```

---

### **6. COUNT_EVENTS - PoÄet (s cachovÃ¡nÃ­m)**

```python
def count_events(self) -> int:
    """VraÅ¥ poÄet vÅ¡ech eventÅ¯"""
    try:
        # Zkus cache
        cache_key = "events:count"
        try:
            cached = self.redis.get(cache_key)
            if cached:
                return int(cached)  # VraÅ¥ z cache
        except:
            pass  # Pokud cache selÅ¾e, pokraÄuj
        
        # Jdi do MongoDB
        collection = self.get_collection("events")
        count = collection.count_documents({})
        
        # Cachuj na 5 minut
        try:
            self.redis.setex(cache_key, 300, str(count))
        except:
            pass
        
        return count
    except Exception as e:
        logger.error(f"âœ— Chyba: {e}")
        return 0
```

**KlÃ­ÄovÃ½ formÃ¡t:**
- `redis.setex(key, ttl, value)` = set + expire
- `ttl=300` = 5 minut

---

### **7. COUNT_TODAY_EVENTS - DneÅ¡nÃ­ (s date range queryem)**

```python
def count_today_events(self) -> int:
    """VraÅ¥ poÄet eventÅ¯ hlÃ¡Å¡enÃ½ch dnes"""
    try:
        # Zkus cache
        cache_key = "events:today"
        try:
            cached = self.redis.get(cache_key)
            if cached:
                return int(cached)
        except:
            pass
        
        # SpoÄÃ­tej od PÅ®LNOCI
        today_start = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
        today_end = today_start + timedelta(days=1)  # ZÃ­tra v 00:00
        
        # MongoDB query: created_at >= dneÅ¡nÃ­ 00:00 AND created_at < zÃ­tra 00:00
        collection = self.get_collection("events")
        count = collection.count_documents({
            "created_at": {
                "$gte": today_start,
                "$lt": today_end
            }
        })
        
        # Cachuj na 5 minut
        try:
            self.redis.setex(cache_key, 300, str(count))
        except:
            pass
        
        return count
    except Exception as e:
        logger.error(f"âœ— Chyba: {e}")
        return 0
```

**Datetime logika:**
```python
# Pokud je teÄ 2026-02-09 14:30:45
today_start = datetime(2026, 2, 9, 0, 0, 0, 0)      # 2026-02-09 00:00:00
today_end = datetime(2026, 2, 10, 0, 0, 0, 0)       # 2026-02-10 00:00:00

# Query hledÃ¡: 2026-02-09 00:00:00 â‰¤ created_at < 2026-02-10 00:00:00
# = VÅ¡echny events hlÃ¡Å¡enÃ© DNES (bÄ›hem dne)
```

---

### **8. DELETE_EVENT - SmaÅ¾**

```python
def delete_event(self, event_id: str) -> bool:
    """SmaÅ¾ event"""
    try:
        from bson.objectid import ObjectId
        collection = self.get_collection("events")
        result = collection.delete_one({"_id": ObjectId(event_id)})
        if result.deleted_count > 0:
            self._invalidate_events_cache()  # VymaÅ¾ cache
            logger.info(f"âœ“ Event smazÃ¡n: {event_id}")
            return True
        return False
    except Exception as e:
        logger.error(f"âœ— Chyba: {e}")
        return False
```

**Logika:**
- `delete_one()` = smaÅ¾ jeden dokument
- `result.deleted_count` = kolik bylo smazanÃ½ch (0 nebo 1)
- Pokud smazÃ¡no: invaliduj cache

---

### **9. _INVALIDATE_EVENTS_CACHE - Vynuluj cache**

```python
def _invalidate_events_cache(self):
    """Vynuluj relevantnÃ­ cache klÃ­Äe"""
    try:
        self.redis.delete("events:all", "events:count")
    except Exception as e:
        logger.warning(f"Cache invalidation failed: {e}")
```

**Kdy se volÃ¡:**
1. `create_event()` â†’ novÃ½ event â†’ seznam se zmÄ›nÃ­ â†’ invaliduj
2. `delete_event()` â†’ event pryÄ â†’ seznam se zmÄ›nÃ­ â†’ invaliduj
3. `clear_all_events()` â†’ vÅ¡echno pryÄ â†’ invaliduj

**PÅ™Ã­klad:**
```
1. db.get_all_events()
   â””â”€ Redis cache: events:all = [event1, event2, event3]

2. db.create_event(new_event)
   â””â”€ ZavolÃ¡ _invalidate_events_cache()
   â””â”€ Redis.delete("events:all")
   â””â”€ Cache je PRYÄŒ

3. db.get_all_events()
   â””â”€ Cache miss â†’ Äte se z MongoDB
   â””â”€ VrÃ¡tÃ­ [event1, event2, event3, new_event]
   â””â”€ Cachuje znovu do Redis
```

---

### **10. HEALTH_CHECK - OvÄ›Å™ spojenÃ­**

```python
def health_check(self) -> Dict[str, bool]:
    """OvÄ›Å™ pÅ™ipojenÃ­ ke vÅ¡em databÃ¡zÃ­m"""
    result = {"mongo": False, "redis": False}
    
    try:
        self.mongo.server_info()
        result["mongo"] = True
    except:
        pass
    
    try:
        self.redis.ping()
        result["redis"] = True
    except:
        pass
    
    return result
```

**VrÃ¡tÃ­:**
```python
{
    "mongo": True,   # MongoDB je dostupnÃ½
    "redis": True    # Redis je dostupnÃ½
}
```

---

## ğŸ¯ KLÃÄŒOVÃ‰ KONCEPTY

| Koncept | Kde se pouÅ¾Ã­vÃ¡ | PÅ™Ã­klad |
|---------|---|---|
| **Lazy loading** | `@property mongo`, `@property redis` | PÅ™ipojÃ­ se aÅ¾ kdyÅ¾ je potÅ™eba |
| **CachovÃ¡nÃ­** | `get_all_events()`, `count_events()` | Redis `setex(key, 300, value)` |
| **Cache invalidation** | `_invalidate_events_cache()` | KdyÅ¾ se zmÄ›nÃ­ data â†’ smaÅ¾ cache |
| **MongoDB query** | `find()`, `count_documents()` | `{"severity": {"$gte": 3}}` |
| **Pagination** | `limit()`, `skip()` | StrÃ¡nkovÃ¡nÃ­ vÃ½sledkÅ¯ |
| **Error handling** | VÅ¡ude `try/except` | Fallback na `None` nebo `[]` |
| **Logging** | `logger.info()`, `logger.error()` | Debug + monitoring |

---

## â“ OTÃZKY NA TEBE

1. **Co by se stalo kdyby si zkusil `db.redis` kdyÅ¾ Redis nenÃ­ spuÅ¡tÄ›nÃ½?**
2. **ProÄ se cachuje jen `limit=100 && skip=0`?**
3. **JakÃ½ je rozdÃ­l mezi `delete_one()` a `delete_many()`?**
4. **Co je `DESCENDING` sorting?**
5. **Jak dlouho Å¾ije cache v Redisu?**

**OdpovÄ›z si - pak na `routes.py`!** ğŸš€
